{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Linear Regression Overview</h4>\n",
    "<ul>\n",
    "<li>Linear Model. Estimated Target = w<sub>0</sub> + w<sub>1</sub>x<sub>1</sub> \n",
    "+ w<sub>2</sub>x<sub>2</sub> + w<sub>3</sub>x<sub>3</sub> \n",
    "+ â€¦ + w<sub>n</sub>x<sub>n</sub><br>\n",
    "where, w is the weight and x is the feature\n",
    "</li>\n",
    "<li>Predicted Value: Numeric</li>\n",
    "<li>Algorithm Used: Linear Regression. Objective is to find the weights w</li>\n",
    "<li>Optimization: Stochastic Gradient Descent. Seeks to minimize loss/cost so that predicted value is as close to actual as possible</li>\n",
    "<li>Cost/Loss Calculation: Squared loss function</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def straight_line(x):\n",
    "    return 5*x + 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def straight_line_weight(weight1,x):\n",
    "    return weight1*x + 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "x_vals = pd.Series(np.random.rand(150)*20)\n",
    "y_vals = x_vals.map(straight_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x1':x_vals,'y':y_vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Feature example\n",
    "# Training Set - Contains several examples of feature 'x' and corresponding correct answer 'y'\n",
    "# Objective is to find out the form y = w0 + w1*x1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=x_vals,y=y_vals)\n",
    "plt.xlabel('Feature x1')\n",
    "plt.ylabel('Target y')\n",
    "plt.grid(True)\n",
    "plt.title('Training Set - One Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Try with different values for W1</h4>\n",
    "Assume that w0 = 8. We need to find out optimal value for w1.\n",
    "Let's try different weights and compute target attribute y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [3,4,5,6,7]\n",
    "y_at_weight = {}\n",
    "\n",
    "for w1 in weights:    \n",
    "    y_calculated = []\n",
    "    y_at_weight[w1] = y_calculated\n",
    "    for x in x_vals:\n",
    "        y_calculated.append(straight_line_weight(w1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=x_vals,y=y_vals, label='actual')\n",
    "plt.scatter(x = x_vals, y = y_at_weight[3], color='r', marker='+', label = 'weight 3')\n",
    "plt.scatter(x = x_vals, y = y_at_weight[4], color='g', label = 'weight 4')\n",
    "plt.scatter(x = x_vals, y = y_at_weight[5], color='b', label = 'weight 5')\n",
    "plt.scatter(x = x_vals, y = y_at_weight[6], color='y', label = 'weight 6')\n",
    "plt.scatter(x = x_vals, y = y_at_weight[7], color='k', marker='+', label = 'weight 7')\n",
    "plt.xlabel('Feature x1')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('Predicted Output for different weights')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Plot Loss at different Weights w1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a set of weights, let's find out loss or cost\n",
    "weight = pd.Series(np.linspace(3,7,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost/Loss Calculation: Squared loss function...a measure of how far is predicted value from actual\n",
    "# Steps :\n",
    "#  For every weight and feature x, compute predicted y\n",
    "#  Now find out loss by = average ((predicted y - actual y)**2)\n",
    "loss_at_wt = []\n",
    "for w1 in weight:\n",
    "    y_predicted = []\n",
    "    for x in x_vals:\n",
    "        y_predicted.append(straight_line_weight(w1,x))\n",
    "    \n",
    "    loss_at_wt.append(((y_vals - y_predicted)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=weight, y=loss_at_wt)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Weight for feature 1')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve - Loss at different weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Loss Function</h4>\n",
    "Squared Loss Function. Loss is the average of squared difference between predicted and actual value.  Squared Loss function not only gives us Loss at a given weight, it also tells us which direction \n",
    "to go to minimize loss. <br>\n",
    "For a given (weight, loss), algorithm finds the slope using calculus/first order derivatives. \n",
    "If negative slope, increase the weight\n",
    "If positive slope, decrease the weight\n",
    "\n",
    "<h4>Learning Rate</h4>\n",
    "Learning Rate decides how much the weight should be increased or decreased.<br>\n",
    "Too big of a change, it will skip the point where loss is minimal.<br>\n",
    "Too small of a change, it will take several iterations to find out where the loss is minimal.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Quadratic Example with two features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at a quadratic example: y = x**2 + x + c\n",
    "# two features: x**2 and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quad_func (x):\n",
    "    return 25*x**2 -80*x + 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quad_func_weight(weight2, x):\n",
    "    #For different weights of quadratic term\n",
    "    # Acutal eqn. 25x^2 - 80x + 64.  We have fixed w1=-80,w0=64. need to find w2.\n",
    "    return weight2*x**2 -80*x + 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quadratic\n",
    "np.random.seed(5)\n",
    "x_vals = pd.Series(np.random.rand(150)*20)\n",
    "y_vals = x_vals.map(quad_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=x_vals,y=y_vals)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Training Set - Two Features')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [0,20,30,50]\n",
    "y_at_weight = {}\n",
    "\n",
    "for w1 in weights:    \n",
    "    y_calculated = []\n",
    "    y_at_weight[w1] = y_calculated\n",
    "    \n",
    "    for x in x_vals:\n",
    "        y_calculated.append(quad_func_weight(w1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=x_vals,y=y_vals, label='actual')\n",
    "plt.scatter(x=x_vals,y=y_at_weight[0], label='weight 0', color='r')\n",
    "plt.scatter(x=x_vals,y=y_at_weight[20], label='weight 20', color='g')\n",
    "plt.scatter(x=x_vals,y=y_at_weight[30], label='weight 30', color='k')\n",
    "plt.scatter(x=x_vals,y=y_at_weight[50], label='weight 50', color='y')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('Predicted Output for different weights')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize Weights for feature 2 \n",
    "weight = pd.Series(np.linspace(-20,70,200))\n",
    "loss_at_wt = []\n",
    "for w1 in weight:\n",
    "    y_calculated = []\n",
    "    for x in x_vals:\n",
    "        y_calculated.append(quad_func_weight(w1,x))\n",
    "    \n",
    "    loss_at_wt.append(((y_vals - y_calculated)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=weight, y=loss_at_wt)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Weight for feature 2')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve - Loss at different weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>Summary</h4>\n",
    "<p><b>Squared Loss Function</b> is parabolic in nature. It has an important property of not only telling us the loss at a given weight, but also tells us which way to go to minimize loss</p>\n",
    "<p><b>Gradient Descent</b> optimization alogrithm uses loss function to move the weights of all the features and iteratively adjusts the weights until optimal value is reached</p>\n",
    "\n",
    "<p><b>Batch Gradient Descent</b> predicts y value for all training examples and then adjusts the value of weights based on loss. It can converge much slower when training set is very large. Training set order does not matter as every single example in the training set is considered before making adjustments</p>\n",
    "\n",
    "<p><b>Stochastic Gradient Descent</b> predicts y value for next training example and immediately adjusts the value of weights.</p> It can converge faster when training set is very large.  Training set should be random order otherwise model will not learn correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
